{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jTSSmG6g0qD"
   },
   "source": [
    "# PART1: Manual Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJNRegrO-Cto"
   },
   "source": [
    "### Reading and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hkL3BtT_bu_",
    "outputId": "612ca3a8-b708-4da3-8596-dcdee16b2820"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4055"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('../resources/Persian Names.txt', 'r', encoding='utf-8').read().splitlines()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ds92oKs-Xzh"
   },
   "source": [
    "### Exploring and counting the bigrams in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PP34CkWe_iwF"
   },
   "outputs": [],
   "source": [
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        bigram = (ch1,ch2)\n",
    "        b[bigram] = b.get(bigram,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYH6WUd-AEmo",
    "outputId": "aaca8e53-6237-436a-97df-d7230ce5b6dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<S>', 'س'), 792),\n",
       " (('ي', 'د'), 729),\n",
       " (('ه', '<E>'), 723),\n",
       " (('س', 'ي'), 699),\n",
       " (('د', 'ا'), 617),\n",
       " (('<S>', 'م'), 609),\n",
       " (('ا', 'ل'), 605),\n",
       " (('ا', 'د'), 540),\n",
       " (('ه', ' '), 539),\n",
       " (('س', 'ا'), 500),\n",
       " (('ا', 'ن'), 496),\n",
       " (('ن', '<E>'), 484),\n",
       " (('ت', '<E>'), 474),\n",
       " (('ا', '<E>'), 464),\n",
       " (('ا', 'ت'), 422),\n",
       " (('ي', '<E>'), 389),\n",
       " (('ل', 'ي'), 337),\n",
       " (('ر', 'ا'), 331),\n",
       " (('<S>', 'ا'), 327),\n",
       " (('ي', 'ن'), 321),\n",
       " (('د', 'ه'), 320),\n",
       " ((' ', 'ا'), 317),\n",
       " (('ح', 'م'), 305),\n",
       " (('م', 'ح'), 292),\n",
       " (('ر', '<E>'), 281),\n",
       " (('ا', 'م'), 277),\n",
       " (('م', 'ي'), 273),\n",
       " (('م', 'د'), 268),\n",
       " (('د', '<E>'), 260),\n",
       " (('<S>', 'ع'), 257),\n",
       " (('م', '<E>'), 256),\n",
       " (('م', 'ه'), 245),\n",
       " (('<S>', 'ن'), 235),\n",
       " (('ل', 'ه'), 233),\n",
       " (('ن', 'ا'), 231),\n",
       " (('ع', 'ل'), 225),\n",
       " (('ي', 'ر'), 223),\n",
       " (('ب', 'ي'), 220),\n",
       " (('م', 'ا'), 219),\n",
       " (('ي', ' '), 212),\n",
       " (('ر', 'ي'), 211),\n",
       " (('د', 'ي'), 205),\n",
       " (('ا', 'ر'), 202),\n",
       " (('ي', 'ا'), 199),\n",
       " (('<S>', 'ف'), 185),\n",
       " ((' ', 'س'), 179),\n",
       " (('ي', 'ه'), 177),\n",
       " (('ل', 'س'), 168),\n",
       " (('<S>', 'ب'), 165),\n",
       " (('ه', 'ر'), 160),\n",
       " (('ا', 'س'), 149),\n",
       " (('ب', 'ا'), 146),\n",
       " (('<S>', 'ح'), 142),\n",
       " (('<S>', 'ر'), 142),\n",
       " (('ن', 'ي'), 138),\n",
       " (('<S>', 'ش'), 137),\n",
       " ((' ', 'ب'), 135),\n",
       " (('ل', '<E>'), 134),\n",
       " (('د', 'م'), 133),\n",
       " (('ي', 'م'), 130),\n",
       " (('ل', 'ا'), 129),\n",
       " (('ف', 'ر'), 126),\n",
       " (('و', 'ر'), 125),\n",
       " (('ا', 'ب'), 121),\n",
       " (('ا', 'ه'), 116),\n",
       " (('ه', 'ا'), 112),\n",
       " (('خ', 'ا'), 106),\n",
       " (('ر', 'ه'), 105),\n",
       " (('ن', ' '), 105),\n",
       " (('ر', 'و'), 105),\n",
       " (('ي', 'ل'), 104),\n",
       " (('ف', 'ا'), 103),\n",
       " (('د', 'ر'), 101),\n",
       " (('ت', 'ا'), 100),\n",
       " (('ع', 'ب'), 99),\n",
       " (('ن', 'و'), 99),\n",
       " (('ب', 'د'), 99),\n",
       " (('ا', 'ز'), 98),\n",
       " (('<S>', 'آ'), 96),\n",
       " (('ح', 'س'), 89),\n",
       " (('ز', '<E>'), 89),\n",
       " (('ن', 'ه'), 87),\n",
       " (('<S>', 'ك'), 86),\n",
       " (('گ', 'ل'), 86),\n",
       " (('ب', 'ه'), 85),\n",
       " (('ا', 'ج'), 84),\n",
       " (('م', 'ر'), 83),\n",
       " (('م', ' '), 82),\n",
       " ((' ', 'م'), 82),\n",
       " (('ا', 'ء'), 80),\n",
       " (('ب', '<E>'), 79),\n",
       " (('<S>', 'ص'), 79),\n",
       " (('ز', 'ا'), 79),\n",
       " (('ر', 'م'), 78),\n",
       " (('<S>', 'خ'), 77),\n",
       " (('ا', 'ي'), 75),\n",
       " (('<S>', 'گ'), 75),\n",
       " (('ت', ' '), 74),\n",
       " (('س', '<E>'), 73),\n",
       " (('د', 'ع'), 73),\n",
       " (('م', 'ن'), 72),\n",
       " (('و', 'ا'), 71),\n",
       " (('س', 'م'), 71),\n",
       " (('ب', 'ر'), 71),\n",
       " (('و', 'ن'), 70),\n",
       " (('<S>', 'ه'), 69),\n",
       " (('<S>', 'پ'), 69),\n",
       " (('<S>', 'ز'), 68),\n",
       " (('ز', 'ه'), 68),\n",
       " (('ن', 'م'), 68),\n",
       " (('ج', 'ا'), 67),\n",
       " (('ش', 'ا'), 66),\n",
       " (('ء', '<E>'), 65),\n",
       " (('ل', 'ل'), 64),\n",
       " ((' ', 'خ'), 63),\n",
       " (('ه', 'د'), 62),\n",
       " (('ر', 'ض'), 62),\n",
       " (('ل', ' '), 62),\n",
       " (('ا', 'ط'), 61),\n",
       " (('ر', 'ح'), 60),\n",
       " (('ه', 'ي'), 60),\n",
       " (('ا', 'ح'), 59),\n",
       " (('ي', 'ب'), 59),\n",
       " (('ح', 'ا'), 58),\n",
       " (('م', 'ل'), 58),\n",
       " (('ح', 'ي'), 56),\n",
       " (('س', 'ن'), 55),\n",
       " (('ج', 'ي'), 55),\n",
       " (('ع', 'ا'), 55),\n",
       " (('پ', 'ر'), 55),\n",
       " (('<S>', 'ي'), 55),\n",
       " (('س', 'ل'), 55),\n",
       " (('ز', 'ي'), 54),\n",
       " (('ك', 'ي'), 54),\n",
       " (('م', 'ع'), 53),\n",
       " (('<S>', 'د'), 53),\n",
       " (('ش', 'ي'), 53),\n",
       " (('ض', 'ا'), 52),\n",
       " (('ط', 'ا'), 52),\n",
       " (('ع', 'ي'), 52),\n",
       " (('م', 'ت'), 52),\n",
       " (('د', 'س'), 52),\n",
       " (('<S>', 'ت'), 52),\n",
       " (('ر', 'س'), 51),\n",
       " (('ي', 'س'), 51),\n",
       " (('ل', 'د'), 51),\n",
       " (('<S>', 'ج'), 50),\n",
       " (('ت', 'و'), 50),\n",
       " ((' ', 'ن'), 49),\n",
       " (('و', 'ي'), 48),\n",
       " (('<S>', 'ط'), 47),\n",
       " (('ن', 'س'), 46),\n",
       " ((' ', 'ع'), 46),\n",
       " (('ط', 'م'), 45),\n",
       " (('و', '<E>'), 45),\n",
       " (('ل', 'م'), 45),\n",
       " (('و', 'د'), 44),\n",
       " (('س', 'ر'), 44),\n",
       " (('ك', 'ر'), 43),\n",
       " (('م', 'س'), 43),\n",
       " (('س', 'و'), 43),\n",
       " (('ر', 'ف'), 43),\n",
       " (('ش', '<E>'), 43),\n",
       " (('گ', 'م'), 43),\n",
       " (('ن', 'د'), 42),\n",
       " (('ي', 'و'), 42),\n",
       " (('س', 'ت'), 42),\n",
       " (('ف', 'ي'), 41),\n",
       " (('و', 'ل'), 41),\n",
       " (('ر', 'ز'), 41),\n",
       " (('ش', 'ه'), 41),\n",
       " (('ي', 'گ'), 41),\n",
       " (('ا', 'ش'), 40),\n",
       " (('ل', 'و'), 40),\n",
       " (('س', 'ع'), 39),\n",
       " (('<S>', 'و'), 39),\n",
       " (('ا', 'ف'), 39),\n",
       " ((' ', 'ر'), 39),\n",
       " (('ك', 'ا'), 39),\n",
       " (('ر', 'ب'), 38),\n",
       " (('<S>', 'ق'), 38),\n",
       " (('و', 'ش'), 38),\n",
       " (('ش', 'ر'), 37),\n",
       " ((' ', 'ز'), 37),\n",
       " (('ص', 'ا'), 37),\n",
       " (('و', 'س'), 37),\n",
       " (('ي', 'ز'), 37),\n",
       " (('ن', 'ج'), 36),\n",
       " (('ك', '<E>'), 36),\n",
       " (('ق', 'ي'), 35),\n",
       " (('ت', 'ي'), 35),\n",
       " (('ص', 'و'), 34),\n",
       " (('ر', 'ش'), 34),\n",
       " (('ف', '<E>'), 34),\n",
       " (('ق', 'ا'), 34),\n",
       " (('د', 'ح'), 33),\n",
       " (('ي', 'ح'), 33),\n",
       " (('<S>', 'غ'), 33),\n",
       " (('ر', 'ج'), 33),\n",
       " (('ر', 'ن'), 33),\n",
       " (('د', 'خ'), 33),\n",
       " (('ن', 'ب'), 32),\n",
       " (('ض', 'ي'), 32),\n",
       " (('ي', 'ت'), 32),\n",
       " (('ش', 'م'), 32),\n",
       " (('ب', 'و'), 31),\n",
       " (('<S>', 'ل'), 31),\n",
       " (('ر', 'ت'), 31),\n",
       " (('ح', 'ب'), 31),\n",
       " (('ر', 'ع'), 31),\n",
       " (('ا', 'و'), 31),\n",
       " (('آ', 'ر'), 31),\n",
       " (('ا', 'ق'), 31),\n",
       " (('ر', 'د'), 31),\n",
       " (('و', 'ز'), 31),\n",
       " (('ل', 'ك'), 31),\n",
       " (('ج', 'م'), 30),\n",
       " (('ف', 'ه'), 30),\n",
       " (('ق', '<E>'), 30),\n",
       " (('ج', '<E>'), 30),\n",
       " (('خ', 'ت'), 30),\n",
       " (('س', ' '), 30),\n",
       " (('ر', 'خ'), 29),\n",
       " (('ل', 'ط'), 29),\n",
       " (('د', 'ن'), 29),\n",
       " (('خ', 'د'), 28),\n",
       " (('س', 'ه'), 28),\n",
       " (('ن', 'ع'), 28),\n",
       " ((' ', 'ج'), 28),\n",
       " (('و', 'م'), 27),\n",
       " (('ج', 'ه'), 27),\n",
       " (('م', 'و'), 27),\n",
       " (('ن', 'ص'), 27),\n",
       " ((' ', 'ف'), 27),\n",
       " (('و', 'ب'), 26),\n",
       " (('ه', 'ن'), 26),\n",
       " (('و', 'ح'), 26),\n",
       " (('ت', 'ر'), 26),\n",
       " ((' ', 'ح'), 26),\n",
       " (('ص', 'د'), 25),\n",
       " (('ا', 'ع'), 25),\n",
       " (('ن', 'گ'), 25),\n",
       " (('ن', 'ر'), 24),\n",
       " (('د', 'ج'), 24),\n",
       " (('ح', 'د'), 24),\n",
       " (('ك', 'و'), 24),\n",
       " (('د', 'ص'), 24),\n",
       " (('ف', 'ت'), 24),\n",
       " (('ل', 'ح'), 24),\n",
       " (('ن', 'ت'), 24),\n",
       " (('ب', ' '), 24),\n",
       " (('د', 'ل'), 24),\n",
       " (('ع', 'ص'), 23),\n",
       " (('ط', 'ي'), 23),\n",
       " (('ك', 'ب'), 23),\n",
       " (('ت', 'ه'), 23),\n",
       " (('ق', 'د'), 23),\n",
       " (('د', 'و'), 23),\n",
       " (('ه', 'م'), 23),\n",
       " (('ظ', 'م'), 22),\n",
       " (('ا', 'ك'), 22),\n",
       " (('ا', 'ئ'), 22),\n",
       " (('ع', 'ز'), 22),\n",
       " (('ي', 'ك'), 22),\n",
       " (('ا', 'ا'), 22),\n",
       " (('ل', 'ع'), 22),\n",
       " (('ط', 'ل'), 22),\n",
       " ((' ', 'گ'), 22),\n",
       " (('ي', 'ق'), 21),\n",
       " (('ط', 'ه'), 21),\n",
       " (('ص', 'ف'), 21),\n",
       " (('ش', 'ك'), 21),\n",
       " (('د', 'ك'), 21),\n",
       " (('ي', 'ف'), 21),\n",
       " (('ق', 'ل'), 21),\n",
       " (('غ', 'ر'), 20),\n",
       " (('ح', ' '), 20),\n",
       " (('ح', '<E>'), 20),\n",
       " (('گ', 'ي'), 20),\n",
       " (('و', 'ه'), 20),\n",
       " (('ه', 'و'), 20),\n",
       " (('م', 'ج'), 19),\n",
       " (('ل', 'ب'), 19),\n",
       " (('ع', 'ط'), 19),\n",
       " (('ذ', 'ر'), 19),\n",
       " (('ي', 'ع'), 19),\n",
       " ((' ', 'ت'), 19),\n",
       " (('ق', 'ه'), 18),\n",
       " (('ر', 'ق'), 18),\n",
       " (('گ', 'ا'), 18),\n",
       " (('و', 'ف'), 18),\n",
       " (('ل', 'ن'), 18),\n",
       " (('ع', 'م'), 18),\n",
       " (('و', 'ك'), 18),\n",
       " (('خ', 'و'), 18),\n",
       " (('ج', ' '), 18),\n",
       " ((' ', 'د'), 18),\n",
       " ((' ', 'آ'), 18),\n",
       " (('ف', 'ض'), 17),\n",
       " (('ض', 'ل'), 17),\n",
       " (('ع', 'ظ'), 17),\n",
       " (('غ', 'ل'), 17),\n",
       " (('م', 'ب'), 17),\n",
       " (('ص', 'غ'), 17),\n",
       " (('ه', 'ل'), 17),\n",
       " (('ح', 'ل'), 17),\n",
       " (('د', 'ب'), 17),\n",
       " (('ح', 'و'), 17),\n",
       " (('خ', 'ر'), 17),\n",
       " (('ف', ' '), 17),\n",
       " (('ا', 'خ'), 17),\n",
       " (('خ', 'ي'), 17),\n",
       " ((' ', 'ك'), 17),\n",
       " (('ك', ' '), 17),\n",
       " (('ل', 'ف'), 16),\n",
       " (('ا', 'ض'), 16),\n",
       " (('ص', 'ر'), 16),\n",
       " (('د', 'ق'), 16),\n",
       " (('ع', 'ف'), 16),\n",
       " (('ح', 'ج'), 16),\n",
       " (('پ', 'ا'), 16),\n",
       " (('آ', 'ي'), 16),\n",
       " (('ص', 'ب'), 16),\n",
       " (('ج', 'ب'), 16),\n",
       " ((' ', 'ص'), 16),\n",
       " (('ر', 'گ'), 15),\n",
       " (('ج', 'و'), 15),\n",
       " (('ه', 'ه'), 15),\n",
       " (('ا', 'ص'), 15),\n",
       " (('ح', 'ه'), 15),\n",
       " (('ع', 'ر'), 15),\n",
       " (('ب', 'ن'), 15),\n",
       " (('<S>', 'ث'), 15),\n",
       " (('پ', 'و'), 15),\n",
       " (('د', 'ف'), 15),\n",
       " (('ب', 'س'), 15),\n",
       " (('ط', 'ف'), 14),\n",
       " (('ي', 'ث'), 14),\n",
       " (('ف', 'خ'), 14),\n",
       " (('ز', 'ر'), 14),\n",
       " (('د', 'ش'), 14),\n",
       " (('س', 'ك'), 13),\n",
       " (('ص', 'م'), 13),\n",
       " (('ع', 'و'), 13),\n",
       " (('ز', 'ن'), 13),\n",
       " (('ج', 'س'), 13),\n",
       " (('س', 'ب'), 13),\n",
       " (('خ', 'ل'), 13),\n",
       " (('ك', 'م'), 13),\n",
       " (('ز', 'ب'), 13),\n",
       " (('ع', 'ه'), 13),\n",
       " (('ب', 'خ'), 13),\n",
       " (('خ', 'ش'), 13),\n",
       " (('ب', 'م'), 13),\n",
       " ((' ', 'پ'), 13),\n",
       " (('آ', 'ق'), 13),\n",
       " (('غ', 'ا'), 13),\n",
       " (('ي', 'ج'), 12),\n",
       " (('ج', 'ع'), 12),\n",
       " (('ل', 'ر'), 12),\n",
       " (('ع', 'ذ'), 12),\n",
       " (('ج', 'د'), 12),\n",
       " (('د', 'پ'), 12),\n",
       " (('ب', 'ل'), 12),\n",
       " (('ك', 'ه'), 12),\n",
       " (('<S>', 'ذ'), 12),\n",
       " ((' ', 'ط'), 12),\n",
       " (('ر', 'ك'), 12),\n",
       " (('ز', 'م'), 12),\n",
       " (('ج', 'ت'), 11),\n",
       " (('ه', 'س'), 11),\n",
       " (('ث', 'م'), 11),\n",
       " (('ح', 'ر'), 11),\n",
       " (('ا', 'ظ'), 11),\n",
       " (('ح', 'ك'), 11),\n",
       " (('د', 'ت'), 11),\n",
       " (('ل', 'ق'), 11),\n",
       " (('ق', 'ر'), 11),\n",
       " (('و', 'ج'), 11),\n",
       " (('ه', 'ز'), 11),\n",
       " (('ز', 'ل'), 11),\n",
       " (('ك', 'ت'), 11),\n",
       " (('ش', 'ن'), 11),\n",
       " (('ع', 'ت'), 11),\n",
       " (('ص', 'ي'), 11),\n",
       " (('ء', 'ا'), 11),\n",
       " (('ت', 'م'), 11),\n",
       " ((' ', 'ي'), 11),\n",
       " (('ه', 'ب'), 11),\n",
       " (('د', 'آ'), 11),\n",
       " (('م', 'ص'), 10),\n",
       " (('ب', 'ت'), 10),\n",
       " (('ث', 'ر'), 10),\n",
       " (('د', 'ط'), 10),\n",
       " (('س', 'ف'), 10),\n",
       " (('ح', 'ن'), 10),\n",
       " (('ج', 'ل'), 10),\n",
       " (('ك', 'ل'), 10),\n",
       " (('ف', 'و'), 10),\n",
       " (('ط', 'و'), 10),\n",
       " (('ع', 'ن'), 10),\n",
       " (('ي', 'خ'), 10),\n",
       " ((' ', 'ل'), 10),\n",
       " (('ن', 'ظ'), 10),\n",
       " (('ط', 'ر'), 10),\n",
       " ((' ', 'ه'), 10),\n",
       " (('ل', 'ت'), 10),\n",
       " (('م', 'ق'), 10),\n",
       " (('ع', 'د'), 10),\n",
       " ((' ', 'ش'), 10),\n",
       " (('ص', 'ن'), 10),\n",
       " (('ل', 'ز'), 10),\n",
       " (('آ', 'ف'), 10),\n",
       " (('گ', 'س'), 9),\n",
       " (('ث', 'ه'), 9),\n",
       " (('ج', 'ر'), 9),\n",
       " (('س', 'ح'), 9),\n",
       " (('م', 'ط'), 9),\n",
       " (('ي', 'ش'), 9),\n",
       " (('س', 'پ'), 9),\n",
       " (('پ', 'ي'), 9),\n",
       " (('ح', 'ت'), 9),\n",
       " (('غ', 'ز'), 9),\n",
       " (('ه', 'ت'), 9),\n",
       " (('س', 'د'), 9),\n",
       " (('ب', 'ع'), 9),\n",
       " (('ظ', 'ي'), 9),\n",
       " (('ش', 'ع'), 9),\n",
       " (('ع', '<E>'), 9),\n",
       " (('ز', 'ت'), 8),\n",
       " (('آ', 'ت'), 8),\n",
       " (('ب', 'ح'), 8),\n",
       " (('م', 'ز'), 8),\n",
       " (('گ', 'و'), 8),\n",
       " (('م', 'ش'), 8),\n",
       " (('ف', 'ش'), 8),\n",
       " (('م', 'خ'), 8),\n",
       " (('خ', '<E>'), 8),\n",
       " (('د', 'د'), 8),\n",
       " (('ف', 'ع'), 8),\n",
       " (('آ', 'ن'), 8),\n",
       " (('ن', 'ق'), 8),\n",
       " (('ز', 'ع'), 8),\n",
       " (('آ', 'غ'), 8),\n",
       " (('ر', 'آ'), 8),\n",
       " (('ش', 'ت'), 7),\n",
       " (('و', 'ث'), 7),\n",
       " (('ف', 'س'), 7),\n",
       " (('آ', 'س'), 7),\n",
       " (('ث', 'ن'), 7),\n",
       " (('ث', 'و'), 7),\n",
       " (('چ', 'ه'), 7),\n",
       " (('ع', 'ق'), 7),\n",
       " (('خ', 'س'), 7),\n",
       " (('ك', 'ن'), 7),\n",
       " (('ظ', 'ر'), 7),\n",
       " (('ت', 'ع'), 7),\n",
       " (('ا', 'غ'), 7),\n",
       " (('<S>', 'ض'), 7),\n",
       " (('ر', 'ص'), 7),\n",
       " (('ب', 'ش'), 7),\n",
       " (('<S>', 'چ'), 7),\n",
       " (('و', 'ت'), 7),\n",
       " (('ت', 'ض'), 6),\n",
       " (('د', 'ث'), 6),\n",
       " (('س', 'ج'), 6),\n",
       " (('ن', 'ف'), 6),\n",
       " (('ت', 'ق'), 6),\n",
       " (('ل', 'ث'), 6),\n",
       " (('آ', 'ذ'), 6),\n",
       " (('گ', '<E>'), 6),\n",
       " (('و', 'گ'), 6),\n",
       " (('ظ', 'ا'), 6),\n",
       " (('ق', 'ب'), 6),\n",
       " (('م', 'ك'), 6),\n",
       " (('ك', 'س'), 6),\n",
       " (('ض', 'ر'), 6),\n",
       " (('ش', ' '), 6),\n",
       " (('ث', 'ا'), 6),\n",
       " ((' ', 'ق'), 6),\n",
       " (('ز', 'س'), 6),\n",
       " (('ب', 'گ'), 6),\n",
       " (('ص', 'ط'), 5),\n",
       " (('ت', 'ب'), 5),\n",
       " (('ئ', 'ز'), 5),\n",
       " (('ر', 'ر'), 5),\n",
       " (('آ', 'م'), 5),\n",
       " (('ث', '<E>'), 5),\n",
       " (('م', 'ژ'), 5),\n",
       " (('ض', 'و'), 5),\n",
       " (('ت', 'ن'), 5),\n",
       " (('م', 'ض'), 5),\n",
       " (('ه', 'ش'), 5),\n",
       " (('ع', 'س'), 5),\n",
       " (('ش', 'و'), 5),\n",
       " (('ع', 'ش'), 5),\n",
       " (('ذ', 'ب'), 5),\n",
       " (('ت', 'ح'), 5),\n",
       " (('ح', 'ش'), 5),\n",
       " (('ق', 'ن'), 5),\n",
       " (('ز', 'د'), 5),\n",
       " (('ژ', 'ا'), 5),\n",
       " (('ف', 'ظ'), 5),\n",
       " (('غ', 'ف'), 5),\n",
       " (('ش', 'ف'), 5),\n",
       " (('ص', 'ل'), 5),\n",
       " (('ئ', 'ي'), 5),\n",
       " (('ر', 'ئ'), 5),\n",
       " (('ئ', 'و'), 5),\n",
       " (('ف', 'ل'), 5),\n",
       " (('ن', 'ز'), 5),\n",
       " (('پ', 'ن'), 5),\n",
       " (('ئ', 'د'), 4),\n",
       " (('آ', 'ز'), 4),\n",
       " (('ي', 'ژ'), 4),\n",
       " (('ز', 'ك'), 4),\n",
       " (('خ', 'ن'), 4),\n",
       " (('و', 'چ'), 4),\n",
       " (('ق', 'و'), 4),\n",
       " (('ض', 'ه'), 4),\n",
       " (('پ', 'ه'), 4),\n",
       " (('گ', 'ن'), 4),\n",
       " (('ق', 'م'), 4),\n",
       " (('<S>', 'ژ'), 4),\n",
       " (('ژ', 'ي'), 4),\n",
       " (('ط', 'ن'), 4),\n",
       " (('م', 'ظ'), 4),\n",
       " (('آ', 'ل'), 4),\n",
       " (('ر', 'ث'), 4),\n",
       " (('ت', 'ك'), 4),\n",
       " (('و', 'ژ'), 4),\n",
       " (('د', 'غ'), 4),\n",
       " (('ل', 'ص'), 4),\n",
       " (('ج', 'ف'), 4),\n",
       " (('ر', 'پ'), 4),\n",
       " (('خ', 'ض'), 4),\n",
       " (('ذ', 'و'), 4),\n",
       " (('ف', 'ق'), 4),\n",
       " (('آ', 'د'), 4),\n",
       " (('ح', 'ف'), 4),\n",
       " (('ظ', 'ه'), 4),\n",
       " ((' ', 'ث'), 4),\n",
       " (('ئ', 'م'), 4),\n",
       " (('و', 'ق'), 4),\n",
       " (('ة', 'ا'), 4),\n",
       " (('ژ', 'گ'), 3),\n",
       " (('ز', 'و'), 3),\n",
       " (('ژ', 'د'), 3),\n",
       " (('و', 'ذ'), 3),\n",
       " (('ي', 'ي'), 3),\n",
       " (('و', 'غ'), 3),\n",
       " (('ش', 'ق'), 3),\n",
       " (('ت', 'س'), 3),\n",
       " (('پ', 'د'), 3),\n",
       " (('ك', 'ف'), 3),\n",
       " (('ف', 'ن'), 3),\n",
       " (('ب', 'ك'), 3),\n",
       " (('ف', 'د'), 3),\n",
       " (('ج', 'ن'), 3),\n",
       " (('ظ', '<E>'), 3),\n",
       " (('و', 'ط'), 3),\n",
       " (('ر', 'ط'), 3),\n",
       " (('ض', 'ح'), 3),\n",
       " (('ط', '<E>'), 3),\n",
       " (('خ', ' '), 3),\n",
       " (('ل', 'ش'), 3),\n",
       " (('گ', 'ر'), 3),\n",
       " (('غ', 'ن'), 3),\n",
       " (('ذ', 'ي'), 3),\n",
       " (('ت', 'خ'), 3),\n",
       " (('د', 'ض'), 3),\n",
       " (('ل', 'ج'), 3),\n",
       " (('ض', '<E>'), 3),\n",
       " (('ش', 'ج'), 3),\n",
       " (('چ', 'ك'), 3),\n",
       " (('و', 'خ'), 3),\n",
       " (('ء', 'س'), 3),\n",
       " (('ع', ' '), 3),\n",
       " (('ب', 'ز'), 3),\n",
       " ((' ', 'چ'), 3),\n",
       " (('چ', 'م'), 3),\n",
       " (('ن', 'ن'), 3),\n",
       " ((' ', 'غ'), 3),\n",
       " (('ص', 'ح'), 3),\n",
       " (('ص', 'ه'), 3),\n",
       " (('و', 'ع'), 3),\n",
       " (('ژ', 'ه'), 2),\n",
       " (('ر', 'ؤ'), 2),\n",
       " (('ؤ', 'ي'), 2),\n",
       " (('غ', '<E>'), 2),\n",
       " (('ه', 'ج'), 2),\n",
       " (('ش', 'ب'), 2),\n",
       " (('ك', 'ش'), 2),\n",
       " (('و', 'و'), 2),\n",
       " (('ن', 'ك'), 2),\n",
       " (('آ', 'و'), 2),\n",
       " (('ظ', 'ف'), 2),\n",
       " (('غ', 'م'), 2),\n",
       " (('ح', 'ق'), 2),\n",
       " (('ح', 'ع'), 2),\n",
       " (('پ', 'گ'), 2),\n",
       " (('ئ', 'ق'), 2),\n",
       " (('ت', 'ش'), 2),\n",
       " (('س', 'ط'), 2),\n",
       " (('ذ', '<E>'), 2),\n",
       " (('ي', 'ص'), 2),\n",
       " (('ق', 'ز'), 2),\n",
       " (('ف', 'ؤ'), 2),\n",
       " (('ؤ', 'ا'), 2),\n",
       " (('ي', 'ض'), 2),\n",
       " (('ض', ' '), 2),\n",
       " (('د', 'ز'), 2),\n",
       " (('ق', 'ص'), 2),\n",
       " (('آ', 'ه'), 2),\n",
       " (('ذ', 'ك'), 2),\n",
       " (('ا', 'پ'), 2),\n",
       " (('ر', 'ل'), 2),\n",
       " (('ل', 'خ'), 2),\n",
       " (('و', 'ض'), 2),\n",
       " (('غ', 'د'), 2),\n",
       " (('ق', 'س'), 2),\n",
       " (('آ', 'ص'), 2),\n",
       " (('ت', 'ص'), 2),\n",
       " (('ت', 'ظ'), 2),\n",
       " (('ث', ' '), 2),\n",
       " (('أ', '<E>'), 2),\n",
       " (('ذ', 'ا'), 2),\n",
       " (('ه', 'پ'), 2),\n",
       " (('ر', 'غ'), 2),\n",
       " (('ل', 'غ'), 2),\n",
       " (('ك', 'ع'), 2),\n",
       " (('ل', 'چ'), 2),\n",
       " (('و', 'ظ'), 2),\n",
       " (('ز', 'گ'), 2),\n",
       " (('آ', 'ئ'), 2),\n",
       " (('ب', 'ص'), 2),\n",
       " (('چ', 'ا'), 2),\n",
       " (('خ', 'م'), 2),\n",
       " (('ف', 'ك'), 2),\n",
       " (('ن', 'ش'), 2),\n",
       " (('د', 'ة'), 2),\n",
       " (('ق', 'ع'), 2),\n",
       " (('ق', 'ت'), 2),\n",
       " (('<S>', 'ظ'), 2),\n",
       " (('ز', 'آ'), 2),\n",
       " (('ض', 'ع'), 2),\n",
       " (('غ', 'ي'), 2),\n",
       " (('ف', 'ط'), 2),\n",
       " (('ز', 'خ'), 2),\n",
       " (('چ', 'ي'), 2),\n",
       " (('و', 'ص'), 2),\n",
       " (('ر', 'ة'), 2),\n",
       " (('ژ', 'ن'), 1),\n",
       " (('پ', 'ژ'), 1),\n",
       " (('ژ', 'م'), 1),\n",
       " (('ن', 'غ'), 1),\n",
       " (('و', 'أ'), 1),\n",
       " (('أ', 'د'), 1),\n",
       " (('ذ', 'ل'), 1),\n",
       " (('غ', 'ض'), 1),\n",
       " (('ض', 'ن'), 1),\n",
       " (('ا', 'ذ'), 1),\n",
       " (('ي', 'ذ'), 1),\n",
       " (('س', 'گ'), 1),\n",
       " (('خ', 'ج'), 1),\n",
       " (('س', 'ق'), 1),\n",
       " (('ع', 'ج'), 1),\n",
       " (('د', 'گ'), 1),\n",
       " (('آ', 'ب'), 1),\n",
       " (('ا', 'ث'), 1),\n",
       " (('آ', '<E>'), 1),\n",
       " (('ي', 'چ'), 1),\n",
       " (('چ', 'ن'), 1),\n",
       " (('ي', 'ظ'), 1),\n",
       " (('ي', 'أ'), 1),\n",
       " (('ب', 'ج'), 1),\n",
       " (('ص', 'ت'), 1),\n",
       " (('گ', 'ش'), 1),\n",
       " (('ص', 'ع'), 1),\n",
       " (('ئ', 'ك'), 1),\n",
       " (('م', 'م'), 1),\n",
       " (('ي', 'غ'), 1),\n",
       " (('آ', 'ج'), 1),\n",
       " (('آ', 'خ'), 1),\n",
       " (('غ', 'و'), 1),\n",
       " (('م', 'غ'), 1),\n",
       " (('ا', 'ژ'), 1),\n",
       " (('غ', 'ج'), 1),\n",
       " ((' ', 'و'), 1),\n",
       " (('ه', 'ق'), 1),\n",
       " (('ي', 'پ'), 1),\n",
       " (('پ', 'ك'), 1),\n",
       " (('ا', 'گ'), 1),\n",
       " (('ه', 'ف'), 1),\n",
       " (('چ', 'ر'), 1),\n",
       " (('غ', 'ع'), 1),\n",
       " (('ح', 'ض'), 1),\n",
       " (('ظ', ' '), 1),\n",
       " (('ر', 'أ'), 1),\n",
       " (('ص', ' '), 1),\n",
       " (('خ', 'ذ'), 1),\n",
       " (('خ', 'ز'), 1),\n",
       " (('ئ', 'ل'), 1),\n",
       " (('ء', 'ب'), 1),\n",
       " (('ش', 'د'), 1),\n",
       " (('ئ', 'ر'), 1),\n",
       " (('ن', 'ل'), 1),\n",
       " (('ه', 'ء'), 1),\n",
       " (('ء', ' '), 1),\n",
       " (('غ', 'ب'), 1),\n",
       " (('ل', 'أ'), 1),\n",
       " (('أ', 'م'), 1),\n",
       " (('ي', 'ط'), 1),\n",
       " (('ق', ' '), 1),\n",
       " (('ل', 'ض'), 1),\n",
       " (('خ', 'ع'), 1),\n",
       " (('ض', 'م'), 1),\n",
       " (('ز', 'ق'), 1),\n",
       " (('گ', 'د'), 1),\n",
       " (('ن', 'چ'), 1),\n",
       " (('ئ', 'ض'), 1),\n",
       " (('غ', ' '), 1),\n",
       " (('ف', 'ص'), 1),\n",
       " (('غ', 'ذ'), 1),\n",
       " (('ك', 'ژ'), 1),\n",
       " (('گ', 'ز'), 1),\n",
       " (('ژ', '<E>'), 1),\n",
       " (('ر', 'چ'), 1),\n",
       " (('پ', 'س'), 1),\n",
       " (('ه', 'ك'), 1),\n",
       " (('خ', 'ص'), 1),\n",
       " (('م', 'ذ'), 1),\n",
       " (('و', 'ة'), 1),\n",
       " (('ة', '<E>'), 1),\n",
       " (('ت', 'د'), 1),\n",
       " (('م', 'ؤ'), 1),\n",
       " (('ؤ', 'م'), 1),\n",
       " (('خ', 'ك'), 1),\n",
       " (('ا', 'آ'), 1),\n",
       " (('ز', 'ط'), 1),\n",
       " (('ن', 'پ'), 1),\n",
       " (('پ', 'ت'), 1),\n",
       " (('ن', 'خ'), 1),\n",
       " (('ق', 'ش'), 1),\n",
       " (('ه', 'ض'), 1),\n",
       " (('ض', 'ت'), 1),\n",
       " (('ز', 'ش'), 1),\n",
       " (('ك', 'ز'), 1),\n",
       " (('ت', 'ف'), 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(), key = lambda kv:-kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of eng alphabet\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "LANG_SIZE = len(chars)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG6tTAa8-xvw"
   },
   "source": [
    "### Counting bigrams in a 2D torch tensor (\"training the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZIvUc4kCSHR_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "N = torch.zeros((LANG_SIZE,LANG_SIZE), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fe_Se9YxSMIb"
   },
   "outputs": [],
   "source": [
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S-4261WzSNyD"
   },
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        \n",
    "        N[ix1,ix2] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2LZg7BE-5Rx"
   },
   "source": [
    "### Visualizing the bigram tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bUwGPNP1SR6n",
    "outputId": "edcebd42-52ad-49b1-c0d0-932b208fc12e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(LANG_SIZE):\n",
    "    for j in range(LANG_SIZE):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX_FbW8f_Rno"
   },
   "source": [
    "### Efficiency! vectorized normalization of the rows, tensor broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwRcVUd4SThv",
    "outputId": "fefabf3f-4fc7-495b-d905-81a717f24fe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0237, 0.0000, 0.0000, 0.0000, 0.0806, 0.0407,\n",
       "        0.0000, 0.0128, 0.0037, 0.0123, 0.0350, 0.0190, 0.0131, 0.0030, 0.0350,\n",
       "        0.0168, 0.1953, 0.0338, 0.0195, 0.0017, 0.0116, 0.0005, 0.0634, 0.0081,\n",
       "        0.0456, 0.0094, 0.0212, 0.0076, 0.1502, 0.0580, 0.0170, 0.0096, 0.0136,\n",
       "        0.0170, 0.0017, 0.0010, 0.0185])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row\n",
    "p = N[0,:].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "xx9GEp2Ortkp",
    "outputId": "a446b535-86ae-4ccf-8e9d-6c378a2182a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ن'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p,num_samples=1, replacement=True, generator=g).item()\n",
    "\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "N-kKQWNr3hSP"
   },
   "outputs": [],
   "source": [
    "#Andrej Edition\n",
    "\n",
    "P = (N+1).float() # N+1 -> Model Smothing\n",
    "P /= P.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nM5cvLBd3-Yc",
    "outputId": "ddc6dfad-34ec-4bc4-e918-9d3b11377ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 40])\n",
      "torch.Size([40, 1])\n"
     ]
    }
   ],
   "source": [
    "print(P.shape)\n",
    "print(P.sum(1,keepdim=True).shape)\n",
    "# 27, 27\n",
    "# 27, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFHwNdqD1wjl",
    "outputId": "fc7c2cf9-2589-4ef2-96b2-7ba7730e5d7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57Ewm0sq_wlq"
   },
   "source": [
    "### Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JWqHY5_ujId",
    "outputId": "a1af4691-08bf-4598-b7dd-976b990ebbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ن.\n",
      "طان.\n",
      "ن.\n",
      "م.\n",
      "آراد.\n",
      "صاداره.\n",
      "دميه.\n",
      "ه بيز.\n",
      "شده بمه.\n",
      "امي.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "  ix = 0\n",
    "  out = []\n",
    "  while True:\n",
    "    p = P[ix]\n",
    "\n",
    "    ix = torch.multinomial(p,num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAjFb2_s_3KP"
   },
   "source": [
    "### Loss function (the negative log likelihood of the data under our model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYtsej0Qw23J",
    "outputId": "b1a72164-2c74-40d4-d19f-160ff2025729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll=tensor(80917.7734)\n",
      "2.491694450378418\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        \n",
    "        prob = P[ix1,ix2]\n",
    "        logprob = torch.log(prob)\n",
    "\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        # print(f'{ch1}{ch2}: {prob:.4f}-> {logprob:.4f}')\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFzJ4lGxhUzq"
   },
   "source": [
    "# PART 2: ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9QF5BAsmpt4"
   },
   "source": [
    "### Creating the bigram dataset for the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZD_7zA5QBU8Y"
   },
   "outputs": [],
   "source": [
    " #crate the training set of bigrams\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcihZ1j3issE",
    "outputId": "444e6599-bbd8-42e5-ccaa-d644de91f02f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 27,  7, 23, 31, 33])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vQyYCz2itfj",
    "outputId": "da541914-2af2-451a-b7ad-edd58747e9ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27,  7, 23, 31, 33,  0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSkZnfKbm8sY"
   },
   "source": [
    "### Feeding integers into neural nets? one-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWpf0nkDiuB3",
    "outputId": "bb479e15-2bfd-4e9d-f404-0b64f8e024e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(xs,num_classes=LANG_SIZE).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "n7P-j2MflceL",
    "outputId": "c0d7ff6b-373e-476f-f02e-817d73c5052b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e38244bf90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rmf22SXnnHue"
   },
   "source": [
    "### The \"neural net\": one linear layer of neurons implemented with matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycbPVtJpmER-",
    "outputId": "c97b46b5-aa98-4462-b6b5-3cb2d0b21247"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3814)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((LANG_SIZE,LANG_SIZE))\n",
    "(xenc @ W)[3,13]\n",
    "# (5,27) @ (27 ,27) -> (5, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeCntZo4q67m",
    "outputId": "2274ba17-40d7-4469-e2f6-e8e040e45191"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3814)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc[3] * W[:,13]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-8IQ7yWwfxB",
    "outputId": "b7e74c9c-d0b4-47d0-a603-44cdeebd7236"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.1863e-01, -2.6280e-01,  1.9280e-01,  1.9076e+00, -1.8484e-01,\n",
       "          1.8351e+00,  2.8744e-01, -3.0345e-01,  1.1859e+00,  1.4396e-01,\n",
       "         -1.9351e-01,  1.9250e+00,  5.1559e-01, -1.1639e+00,  7.8952e-02,\n",
       "          4.2444e-01,  2.5433e-03, -1.0926e+00,  9.6743e-01,  2.1447e-01,\n",
       "          5.7677e-01, -1.7519e+00, -1.0232e+00,  1.8821e+00,  1.1104e+00,\n",
       "          2.0274e+00,  1.1875e+00,  9.7035e-02,  2.4402e-01,  1.2993e+00,\n",
       "         -1.3326e+00,  1.8801e-01, -9.1189e-01,  4.4453e-01, -7.3791e-01,\n",
       "         -2.4837e-01,  4.0277e-01,  6.3645e-01,  1.5825e+00, -2.6408e+00],\n",
       "        [ 6.8283e-01, -3.1976e+00,  2.2090e+00,  1.3580e-01, -1.1706e-01,\n",
       "          7.0321e-01,  2.8715e-01, -1.1209e-01, -1.5281e-01,  2.5665e-01,\n",
       "         -1.4520e-01,  1.5066e+00, -1.0189e+00,  6.3589e-01, -8.7110e-01,\n",
       "         -3.8150e-01,  9.1894e-01,  1.6130e-01,  1.7747e+00, -1.0212e+00,\n",
       "          1.6274e+00,  5.9338e-01,  5.2452e-01,  2.0195e+00,  1.0760e+00,\n",
       "         -3.3299e-01,  1.0949e-01, -4.6962e-01,  1.0934e-01,  4.2635e-01,\n",
       "         -1.4583e-01,  4.5597e-01,  4.8721e-01, -6.0087e-01, -1.0003e+00,\n",
       "         -4.1425e-01,  1.0331e+00,  1.3385e-01, -2.6810e-02, -1.3660e+00],\n",
       "        [-2.7962e+00,  3.0599e-01, -6.1245e-01, -1.3842e+00,  5.1861e-01,\n",
       "          1.3256e+00, -2.6290e+00,  4.7911e-02, -7.8933e-01,  1.8806e+00,\n",
       "          1.7186e+00,  1.3480e+00, -2.7702e-01,  2.0689e-01, -1.1163e+00,\n",
       "          1.3728e+00,  1.7868e-02,  8.4038e-01,  6.4893e-01,  7.0861e-01,\n",
       "          6.8045e-01, -1.0231e+00, -3.3312e+00,  1.3962e+00,  9.5985e-01,\n",
       "         -6.2447e-01,  1.0842e+00, -1.2021e+00,  2.6936e+00, -8.6425e-01,\n",
       "         -8.7706e-01, -8.1390e-01,  8.6117e-01, -4.0843e-01,  1.1687e+00,\n",
       "         -5.7963e-01, -1.0532e+00, -6.5280e-01,  1.3671e+00,  8.7484e-01],\n",
       "        [ 8.8800e-01, -1.5625e+00, -1.6671e-02,  6.7997e-01,  7.8110e-01,\n",
       "          1.9865e+00,  2.4345e+00,  1.6462e-01,  9.1937e-01,  1.2106e+00,\n",
       "          6.5907e-01, -1.4633e+00,  8.0759e-01,  3.8143e-01, -7.8672e-01,\n",
       "         -1.2127e+00, -4.3709e-02, -1.1835e+00,  4.5659e-01, -1.5402e+00,\n",
       "         -2.1812e+00, -1.2503e+00,  2.3000e-01,  9.6571e-01,  2.2130e+00,\n",
       "          5.2742e-01, -1.2215e-01,  3.7402e-01, -2.6582e+00,  2.4269e-01,\n",
       "          3.8516e-01, -4.4593e-01,  1.2837e+00,  2.3319e-01, -8.3965e-01,\n",
       "         -1.0702e+00,  2.1985e+00,  7.5668e-01,  7.5463e-01, -1.4172e-01],\n",
       "        [-6.7231e-01, -1.2670e+00,  4.0526e-01, -4.4476e-01, -1.3868e+00,\n",
       "         -8.5584e-01, -2.1384e-01,  4.0724e-02,  6.5565e-01, -1.1432e+00,\n",
       "         -8.1582e-01,  3.2222e-03, -1.1238e+00, -4.0107e-01,  8.4857e-01,\n",
       "          2.5077e-01,  1.0948e-01, -8.1585e-01, -3.7766e-01,  1.4318e+00,\n",
       "          5.6277e-01,  7.5744e-01, -4.9361e-02, -1.8727e+00,  1.5843e-01,\n",
       "         -9.0464e-01,  7.3088e-01,  5.8066e-01, -1.6910e+00, -1.0598e+00,\n",
       "         -9.5496e-02, -1.1886e+00,  1.8149e+00, -1.9237e-01, -1.8348e+00,\n",
       "         -1.7474e+00,  7.0642e-01, -2.7654e-01,  1.1609e+00,  1.3101e+00],\n",
       "        [-1.0832e+00, -5.2958e-01, -1.5435e-01, -1.0092e+00, -1.1570e+00,\n",
       "         -1.3842e+00,  1.9214e+00, -1.7199e+00, -4.7363e-01,  7.6546e-01,\n",
       "          2.1330e-01, -2.6781e-01, -1.4324e+00,  2.0416e-01, -4.7359e-01,\n",
       "         -3.9193e-02, -2.5285e-01, -1.1719e+00,  5.0955e-01,  5.6649e-01,\n",
       "          9.3249e-02, -7.0984e-01,  2.2750e-01,  9.0203e-01,  1.0075e+00,\n",
       "         -3.2981e-01,  4.1393e-01,  1.0457e+00,  1.1534e+00,  9.2349e-01,\n",
       "          3.6843e-02, -7.9161e-01, -8.4944e-01, -2.0342e-02,  1.3803e+00,\n",
       "         -7.3372e-02, -4.1288e-01,  7.1431e-02,  3.7707e-01, -2.4478e-02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc @ W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGYJUsAAu9Rm"
   },
   "source": [
    "### transforming neural net outputs into probabilities: the softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yp9L-fFcrPf3",
    "outputId": "143d3aa8-7f90-4539-e0d1-fca3b55f43fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0298, 0.0091, 0.0144, 0.0801, 0.0099, 0.0745, 0.0158, 0.0088, 0.0389,\n",
       "         0.0137, 0.0098, 0.0815, 0.0199, 0.0037, 0.0129, 0.0182, 0.0119, 0.0040,\n",
       "         0.0313, 0.0147, 0.0212, 0.0021, 0.0043, 0.0780, 0.0361, 0.0902, 0.0390,\n",
       "         0.0131, 0.0152, 0.0436, 0.0031, 0.0143, 0.0048, 0.0185, 0.0057, 0.0093,\n",
       "         0.0178, 0.0225, 0.0578, 0.0008],\n",
       "        [0.0270, 0.0006, 0.1244, 0.0156, 0.0121, 0.0276, 0.0182, 0.0122, 0.0117,\n",
       "         0.0177, 0.0118, 0.0616, 0.0049, 0.0258, 0.0057, 0.0093, 0.0342, 0.0160,\n",
       "         0.0806, 0.0049, 0.0695, 0.0247, 0.0231, 0.1029, 0.0401, 0.0098, 0.0152,\n",
       "         0.0085, 0.0152, 0.0209, 0.0118, 0.0215, 0.0222, 0.0075, 0.0050, 0.0090,\n",
       "         0.0384, 0.0156, 0.0133, 0.0035],\n",
       "        [0.0007, 0.0166, 0.0066, 0.0031, 0.0206, 0.0461, 0.0009, 0.0129, 0.0056,\n",
       "         0.0803, 0.0683, 0.0472, 0.0093, 0.0151, 0.0040, 0.0483, 0.0125, 0.0284,\n",
       "         0.0234, 0.0249, 0.0242, 0.0044, 0.0004, 0.0495, 0.0320, 0.0066, 0.0362,\n",
       "         0.0037, 0.1811, 0.0052, 0.0051, 0.0054, 0.0290, 0.0081, 0.0394, 0.0069,\n",
       "         0.0043, 0.0064, 0.0481, 0.0294],\n",
       "        [0.0290, 0.0025, 0.0117, 0.0235, 0.0260, 0.0869, 0.1360, 0.0141, 0.0299,\n",
       "         0.0400, 0.0230, 0.0028, 0.0267, 0.0175, 0.0054, 0.0035, 0.0114, 0.0036,\n",
       "         0.0188, 0.0026, 0.0013, 0.0034, 0.0150, 0.0313, 0.1090, 0.0202, 0.0105,\n",
       "         0.0173, 0.0008, 0.0152, 0.0175, 0.0076, 0.0430, 0.0150, 0.0051, 0.0041,\n",
       "         0.1074, 0.0254, 0.0253, 0.0103],\n",
       "        [0.0103, 0.0057, 0.0304, 0.0130, 0.0051, 0.0086, 0.0164, 0.0211, 0.0390,\n",
       "         0.0065, 0.0090, 0.0203, 0.0066, 0.0136, 0.0473, 0.0260, 0.0226, 0.0090,\n",
       "         0.0139, 0.0848, 0.0356, 0.0432, 0.0193, 0.0031, 0.0237, 0.0082, 0.0421,\n",
       "         0.0362, 0.0037, 0.0070, 0.0184, 0.0062, 0.1244, 0.0167, 0.0032, 0.0035,\n",
       "         0.0411, 0.0154, 0.0647, 0.0751],\n",
       "        [0.0064, 0.0111, 0.0162, 0.0069, 0.0059, 0.0047, 0.1292, 0.0034, 0.0118,\n",
       "         0.0407, 0.0234, 0.0145, 0.0045, 0.0232, 0.0118, 0.0182, 0.0147, 0.0059,\n",
       "         0.0315, 0.0333, 0.0208, 0.0093, 0.0238, 0.0466, 0.0518, 0.0136, 0.0286,\n",
       "         0.0538, 0.0600, 0.0476, 0.0196, 0.0086, 0.0081, 0.0185, 0.0752, 0.0176,\n",
       "         0.0125, 0.0203, 0.0276, 0.0185]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = (xenc @ W) #log counts\n",
    "counts = logits.exp() #equivalent N\n",
    "prob = counts /counts.sum(1, keepdims=True)\n",
    "prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdEaCL7swPIH",
    "outputId": "176a683a-d885-4025-c437-dde2db073baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0298, 0.0091, 0.0144, 0.0801, 0.0099, 0.0745, 0.0158, 0.0088, 0.0389,\n",
       "        0.0137, 0.0098, 0.0815, 0.0199, 0.0037, 0.0129, 0.0182, 0.0119, 0.0040,\n",
       "        0.0313, 0.0147, 0.0212, 0.0021, 0.0043, 0.0780, 0.0361, 0.0902, 0.0390,\n",
       "        0.0131, 0.0152, 0.0436, 0.0031, 0.0143, 0.0048, 0.0185, 0.0057, 0.0093,\n",
       "        0.0178, 0.0225, 0.0578, 0.0008])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0] # -> what should come after '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q7ci4XYypd_"
   },
   "source": [
    "### Summary, Preview to next steps, reference to Micrograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLL5rBUWykMi",
    "outputId": "3dfa0187-8106-4c6c-de44-fb05d0318abd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 27,  7, 23, 31, 33])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0rORz25zL_W",
    "outputId": "2eb73c76-8a9e-43f0-8276-6824f043910a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27,  7, 23, 31, 33,  0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GRWt8IMYzNBB"
   },
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((LANG_SIZE, LANG_SIZE), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "H1rfLIMnzO42"
   },
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=LANG_SIZE).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # (fake) counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# btw: the last 2 lines here are together called a 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ysPBqXw6zQdI",
    "outputId": "17b30d9d-e2ef-48f7-bad8-f1fed10af252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: .ف (indexes 0,27)\n",
      "input to the neural net: 0\n",
      "label (actual next character): 27\n",
      "probability assigned by the net to the the correct character: 0.005299513228237629\n",
      "log likelihood: -5.240140438079834\n",
      "negative log likelihood: 5.240140438079834\n",
      "--------\n",
      "bigram example 2: فا (indexes 27,7)\n",
      "input to the neural net: 27\n",
      "label (actual next character): 7\n",
      "probability assigned by the net to the the correct character: 0.004350846167653799\n",
      "log likelihood: -5.437385082244873\n",
      "negative log likelihood: 5.437385082244873\n",
      "--------\n",
      "bigram example 3: اط (indexes 7,23)\n",
      "input to the neural net: 7\n",
      "label (actual next character): 23\n",
      "probability assigned by the net to the the correct character: 0.040493037551641464\n",
      "log likelihood: -3.20662522315979\n",
      "negative log likelihood: 3.20662522315979\n",
      "--------\n",
      "bigram example 4: طم (indexes 23,31)\n",
      "input to the neural net: 23\n",
      "label (actual next character): 31\n",
      "probability assigned by the net to the the correct character: 0.026163851842284203\n",
      "log likelihood: -3.643376588821411\n",
      "negative log likelihood: 3.643376588821411\n",
      "--------\n",
      "bigram example 5: مه (indexes 31,33)\n",
      "input to the neural net: 31\n",
      "label (actual next character): 33\n",
      "probability assigned by the net to the the correct character: 0.04570711404085159\n",
      "log likelihood: -3.0855014324188232\n",
      "negative log likelihood: 3.0855014324188232\n",
      "==================\n",
      "average negative log likelihood, i.e. loss = 4.122605800628662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  # print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('==================')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyxlFA1yC193"
   },
   "source": [
    "### Vectorized loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "P8p96wFgEcXX"
   },
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((LANG_SIZE, LANG_SIZE), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "m0C9nKeEEe7y"
   },
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=LANG_SIZE).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # (fake) counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAf6Tg6l04sq",
    "outputId": "4e1ec8a1-5cf4-4cfc-dafe-37d51858d3e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.29724645614624"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdQqlmlxD02C"
   },
   "source": [
    "### Backward and update, in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "sC4uXvhkDVK3"
   },
   "outputs": [],
   "source": [
    "W.grad = None # set the gradiant to Zero\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvsxmwPhFYp2",
    "outputId": "f3a6da3e-aa63-4b64-db36-58c0afddde4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.shape=torch.Size([40, 40])\n",
      "W.grad.shape=torch.Size([40, 40])\n"
     ]
    }
   ],
   "source": [
    "print(f'{W.shape=}')\n",
    "print(f'{W.grad.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "bubdiILuFgjI"
   },
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiAZD86NHRFo"
   },
   "source": [
    "# Putting Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GoQmRUDGJhe",
    "outputId": "b21edda6-f150-4fc0-dc94-2c95aeacbb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  32475\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((LANG_SIZE,LANG_SIZE), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuUdwnJdKcyM",
    "outputId": "3ec62eab-4f2e-40e4-a74f-61047deef7c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.514431953430176\n",
      "2.514009714126587\n",
      "2.5136187076568604\n",
      "2.5132553577423096\n",
      "2.5129175186157227\n",
      "2.5126023292541504\n",
      "2.512308120727539\n",
      "2.5120327472686768\n",
      "2.511775016784668\n",
      "2.51153302192688\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=LANG_SIZE).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "  if k%10==0:\n",
    "    print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtNCl2H8M8Bm"
   },
   "source": [
    "# Sampling from the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kiJqEcJBKgMC",
    "outputId": "d4855a6a-23d2-4fff-cbf2-f63fa9a736da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ن.\n",
      "طان.\n",
      "ن.\n",
      "م.\n",
      "آراد.\n",
      "صاداره.\n",
      "دميه.\n",
      "ه بيز.\n",
      "شره بمه.\n",
      "امي.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=LANG_SIZE).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
